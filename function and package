패키지 ------------------------------------------------------------------------ '패키지명' cheat sheet 구글하면 해당 패키지 자주쓰이는거 정리해놓은 이미지 나옴
  가. 기능패키지
	install.packages('openxlsx')
	install.packages('dplyr') 
	install.packages('tidyr')
	iinstall.packages("stringr")
	install.packages('lubridate')
	install.packages('ggplot2')
	install.packages("ggthemes") - 그래프 스타일?
	install.packages("sampling")
	install.packages("reshape")
	install.packages("psych") - 상관관계 그래프, 8
	install.packages("PerformanceAnalytics")
	install.packages("corrplot") - 상관관계 기본 그래프
	install.packages("laercio") - 분산분석, 사후검정 함수패키지
	install.packages("gmodels") - 카이제곱
	install.packages("DataExplorer") -- 전체적으로 보고서 만들어주는 함수, 전체적인 데이터파악할 때 좋을 듯  

  나. 데이터 패키지
	install.packages("hflights") -- 요건 데이터 쓰려고
	install.packages("gapminder") - 각 나라별 5년 주기로 기대수명, 총생산GDP 지수 데이터 
	install.packages("moonBook") - acs 데이터


라이브러리 -------------------------------------------------------------------
  가. 기본 라이브러리
	library(openxlsx)
	library(dplyr)
	library(tidyr)
	library(stringr)
	library(lubridate)
	library(ggplot2)
	library(ggthemes)
	library(sampling)
	library(reshape)
	library(psych)
	library(PerformanceAnalytics)
	library(corrplot)
	library(laercio)
	library(gmodels)
	library(DataExplorer)
	
  나. 데이터 라이브러리
	library(hflights)
	library(gapminder)
	library(moonBook)
--------------------------------------------------------------------------------------------

1주차

rm(list = ls())

seq (시작값, 마지막값, by(증가분) or length(길이지정)) 
rep (반복할 값, 반복횟수(each:각각, length:길이만큼, tmies: 반복 출력)

factor(obj, levels=변수값, labels=요인이름)
ordered(obj, levels=변수값, labels=요인이름)

matrix(data, byrow = T, ncol = 3) : 행렬을 생성하기 위해 사용, byrow = 행 기준 행렬을 생성(기본적으로 열로 기준이 되어있다.)
rownames()
colnames()

array() : 행렬을 2차원 이상으로 확장 , array(1:8, c(2,2,2))  
dim() : arr <- c(1:24)                                
        dim(arr) <- c(3,4,2) 
        
data.frame() : 이미 생성되어 있는 벡터들을 결합하여 데이터 프레임을 생성
list() : 서로 다른 형태(mode)의 자료를 포함하는 하나의 객체

----------------------------------------------------------------------------------------------------------------------

2주차

getwd() : 작업 폴더 확인하기 
setwd() : 작업 폴더 지정하기
View() : 데이터보기

read.csv('test.csv') : 데이터 불러오기
read.csv('pop_seoul_euckr.csv', fileEncoding='euc-kr') : 글자가 깨지는 경우에 사용하는 부수적인 함수 

head(pop_seoul)
tail(pop_seoul, n=10) 
str(pop_seoul)
summary(pop_seoul)

read.table( ) :  txt파일 불러오기
write.csv(저장할객체, file='경로/이름') : 객체 내보내기

install.packages('openxlsx')
library(openxlsx) : 원래는 없었던 read.xlsx( ) 함수 사용가능 

read.xlsx('test.xlsx', sheet=2, startRow=3) 

new_data <- readRDS("iris.RDS")
saveRDS(new_data, file = "new_iris.RDS") : 변수자체를 저장하는 느낌! 작업이력!

load("iris.RData") : 변수를 묶어서 저장 
save.image("iris_image.RData") : image 저장 ----요부분 잘 모르겠네, 변수저장

data$CC <- 1 : 열추가

sample(1:6,10, replace = T) : 랜덤 추출(replace = T는 중복가능)
subset(data, 조건)

rbind(data1, data2...)
cbind(data1, data2...)

my_data$age_grp = cut(my_data$age, 
                      breaks=c(10,20,30,40), 
                      include.lowest=TRUE, #왼쪽꺼 포함할꺼냐!(이상), 포함안하면 (초과)느낌
                      right=FALSE,
                      labels=c('10_19','20_29','30_39'))
                      
merge(데이터1, 데이터2, by.x='첫번째데이터의 기준변수', by.y='두번째...') : 기준변수가 같을 때는 'by='으로 한번에 지정가능
 - all.x, all.y, all=TRUE : 짝이 없는 데이터까지 포함시킬지 여부 옵션 **중요

-------------------------------------------------------------------------------------------------------------------

3주차

조건문
if( 조건1 ) {
  # 표현식 1
} else if (조건2) {
  # 표현식 2
} else {
  # 표현식 3
}
ifelse(조건,참,거짓)


루프문
expand.grid(data1, data2) : 벡터에 있는 요소이 모든 조합을 작성
prob <- c("1" = 1/8, "2" = 1/8, "3" = 1/8, "4" = 1/8, "5" = 1/8, "6" = 3/8)
rolls$prob1 <- prob[rolls$Var1] 
rolls$prob2 <- prob[rolls$Var2]
rolls$prob <- rolls$prob1 * rolls$prob2

for (value in that) {
  this
  print(value) #중간 과정 보려고!
}

*for문과 while 차이 
 for문은 몇번 돌아야하는지가 명확히 나와있고
 while은 조건을 만족할 때까지 반복하는 것! 

i <- 1
while (i < 6) {
  print(i)
  i = i+1
}

k <- 1
repeat {
  k <- k+3
  if (k < 5) break}

apply(x,1,sum) : x행렬을 행 방향으로 sum()함수를 사용해줘, for문을 좀 더 쉽게 사용하는 함수?
apply(iris[, 1:4], 2, sum)

lapply() : 벡터, 리스트 또는 표현식에 함수를 적용하여 그 결과를 리스트로 반환
lapply(iris[, 1:4], mean)

sapply() : lapply와 유사하지만 결과를 벡터, 행렬 또는 배열로 반환
sapply(iris[, 1:4], mean)

tapply( ) : 벡터에 있는 데이터를 특정 기준에 따라 그룹으로 묶은 뒤 각 그룹마다 주어진 함수를 적용하고 그 결과를 반환
tapply(iris$Sepal.Length, iris$Species, mean)

mapply(mean, iris[, 1:4]) : sapply의 확장된 버전으로, 여러 개의 벡터 또는 리스트를 인자로 받아 함수에 각 데이터의 첫째 요소들을 적용한 결과, 둘째 요소들을 적용한 결과, 
                            셋째 요소들을 적용한 결과 등을 반환


rowSums(iris[, 1:4])
colSums(iris[, 1:4])

unlist() : 리스트 구조를 벡터로 변환한다.
do.call() : 함수를 리스트로 주어진 인자에 적용하여 결과를 반환한다.

sapply(iris, class) : 변수 구조 확인할떄 많이 쓴다.
str(iris)

------------------------------------------------------------------------------------------------------------------------------------------------------

4주차 
install.packages('dplyr') 
library(dplyr)

slice(데이터명, 잘라서가져올 행)
filter(데이터명, 조건)
arrange(데이터명, 정렬기준변수1, 정렬기준변수2, ...) : 내림차순(Descending)으로 정렬할 때는 'desc' 옵션 활용
select(데이터명, 컬럼)
distinct( delivery, 업종) : 시간이 많이 걸림
unique() : 중복값 제
mutate(delivery, 새요일=paste0(요일, '요일')) 기존 변수를 활용한 임시 변수 만들기

paste0() : ex) d열 데이터를 새로 만드는데 c열에 있는 데이터 참고해서 일괄적으로 데이터에 추가할때?
           mutate(delivery, 새요일=paste0(요일, '요일'))
paste0('H', substr(names(subway_2017)[6:25], 1, 2))

count(delivery, 시군구) : 그룹별 개수 세기 
group_by(delivery, 시군구) : 그룹별 지정
summarize( )로 요약 하기
summarise(delivery, mean(통화건수), 
                    m = min(통화건수), 
                    M = max(통화건수))

top_n(delivery, 5, 통화건수)

------------------------------------------------------------------------------------------------------------------------------------------------------

5주차

spread(데이터이름, 기준변수이름, 나열할 값)
replace_na(list(변수1=값, 변수2=값, ...)) : 대체
drop_na(결측값을 찾을 변수1, 변수2, ...)  : 삭제
gather(데이터이름, 새기준변수이름, 새변수이름, 모을 변수들) :
complete( )로 빠져있는 조합 채우기 : 모든 경우의 수에 행을 추가해서 na값을 대체 

str_detect(x, "e") e가 들어가 있냐 없냐! -> True False 형으로 반환
str_count(x,"a") 각 데이터에 a가 몇 개씩 들어가있냐!
str_which(x,"e") 위치, 몇번째 데이터에 포함되어있냐!
str_locate(x,"a") 텍스트 내에서의 어느 위치에 있는거야? -> 반환
str_subset(x,"r") x데이터에서 r이 포함되어있는걸 뽑아와!!

str_replace("apple","p","l") : 첫자만 
str_replace_all("apple","p","l") : 데이터를 날릴 때?(대체) 할 때 사용, ‘p’를 ‘l’로 바꿔줘!!

str_to_lower("STRING") : 소문자로
str_to_upper("string") : 대문자로
str_to_title("string") : 첫 글자만

as.factor(x) : 주어진 객체 x를 팩터ymd('20200110')
mdy('January 10th 2020')
dmy('10-jan-2020')
ymd('820327')
ymd(820327)
--- as.Date는 잘안쓴다. 

로 변환
as.numeric(x) : 주어진 객체 x를 숫자를 저장한 벡터로 변환
as.character(x) : 주어진 객체 x를 문자열을 저장한 벡터로 변환
as.matrix(x) : 주어진 객체 x를 행렬로 변환
as.data.frame(x) : 주어진 객체 x를 데이터 프레임으로 변환

ymd('20200110')
mdy('January 10th 2020')
dmy('10-jan-2020')
ymd('820327')
ymd(820327)

-------------------------------------------------------------------------------------------

6주차

install.packages('ggplot2')
library(ggplot2)

options("scipen" = 100) --- y축에 숫자 너무 커서 정수로 만들어주고싶을 때 

점그래프
ggplot(data1) + --------------------1. 도화지 그리기
  aes(x = gdpPercap) + ------------2. x축 지정
  aes(y = lifeExp) + ----------------3. y축 지정
  geom_point() + -----------------4. 나타낼 그림
  aes(color = continent) -----------5. 색 지정
  aes(shape = continent) ----------6. 모양 지정
  aes(size = pop) -----------------7. 크기 지정
  aes(alpha = 0.7) -----------------8. 투명도 지정
  
막대그래프 : 막대그래프는 color이 아닌 fill로 사용,color하면 겉에만 칠해짐 
geom_bar() 

facet_grid(~year) : 특정 변수 구분

박스 그래프 geom_boxplot() : 데이터 분포를 보여주는 그래프 
geom_boxplot()

히스토그램 : 직관적이라 좋긴하지만, 넓이, 기준에 따라 데이터분포가 다르게 보일 수 있음.
geom_boxplot()

선 그래프 : 여러 그룹을 그리고 싶을 경우, 라인그래프 안에서 그룹까지 지정해주면 된다. 
geom_line()

gapminder %>%
  group_by(year,continent) %>%
  dplyr::summarise(mean = mean(lifeExp)) %>%
  ggplot(aes(x=year, y=mean , group=continent ,color= continent)) + geom_line()

열지도(heatmap)
	agg2 %>% 
	  ggplot(aes(x=region, y=bmi_grp, fill=Q90)) +
	  geom_tile()
          
나머지 테마변경, 범례 수정, 축 변경, 색 변경, 글자크기, 각도 수정 수업자료 참고

--------------------------------------------------------------------------------------------------------

7주차 : 기초통계(기술통계, 추론통계)

평균
mean(x,na.rm=FALSE)

분산
var(x,na.rm=FALSE)

표준편차
sd(x,na.rm=FALSE)

사분위수
quantile(1:10,0.7)

요약
summary(1:11)

table(x) : 팩터의 각 레벨(level)별 빈도수를 구한다.
which.max(table(x)) : 가장 큰 값이 저장된 셀의 색인은 3
names(table(x))[3] : 가장 큰 값이 저장된 셀의 이름

주변비율, 데이터비중
x1 <- data.frame(x1=sample(1:5,20,replace = T),x2=sample(1:5,20,replace = T))
prop.table(table(x1)) 
prop.table(table(x1),1)
prop.table(table(x1),2)


추출
랜덤추출
sample(1:10, 5, replace=TRUE) : replace(복원 추출 여부)
sample(x,size,replace = )

층화추출
install.packages("sampling")
library(sampling)
x <- strata(stratanames = "Species", size=c(3, 3, 3), method="srswor", data=iris)


이산확률 분포
RB = sample( c(0,1) , 400 , prob = c(0.4,0.6), replace=T) : 0.4,0.6 비율로 뽑고싶어

ggplot(NULL) +
  geom_bar(aes(x = as.factor(RB), fill = as.factor(RB))) +
  theme_bw() +
  xlab("") + ylab("") + #---이게 뭐였찌 
  scale_x_discrete(labels = c("실패","성공")) +
  theme(legend.position = 'none')  
  
 
이항분포 추출
rbinom(n=100,size=5,prob=0.5) : 동전을 5번 던졌을 경우 앞면이 나오는 횟수 (n이 어느정도 크면 정규분포 형태를 보인다. 중심극한정리)

확률을 확인
dbinom(x=3,size=5,prob=0.5) #3번 앞면
dbinom(x=4,size=5,prob=0.5) #4번 앞면이 나올 확률!

누적 확률 확인
pbinom(q=2, size = 5, prob = 0.5) # 2 이하 성공
pbinom(q=3, size = 5, prob = 0.5) # 3 이하 성공


연속 확률 분포
R = rnorm(n = 100000, mean = 0, sd = 1)

rnorm() : 평균과 분산에 해당하는 랜덤 샘플
dnorm() : 확률 밀도함수
pnorm() : 누적 분포함수
qnorm() : 분위수 함수

-------------------------------------------------------------------------------------------------------------------------------

8주차
install.packages("moonBook")
install.packages("psych")
install.packages("PerformanceAnalytics")
install.packages("corrplot")

cor(acs2,use="na.or.complete") : 상관관계 숫자 표현
pairs.panels(acs2) : 상관관계 그래프 표현
chart.Correlation(acs2, histogram=TRUE, pch=19) : 상관관계 그래프 표현

plot(dat$a,dat$b) : 데이터 분포
abline(lm(dat$b~dat$a)) : 데이터 분포 선그리기
cor(dat$a,dat$b) : 상관계수 

상관계수할 때는 아웃라이어를 고민해야한다, 신경써야한다. 민감하다. 

corrplot(cor(acs2,use="na.or.complete"),method="number")


집단에 대한 평균비교 t-test----------
1. 박스플랏으로 데이터분포 확인
ggplot(t_data,aes(x=factor(group),y=score,fill=factor(group))) + geom_boxplot()

2. 정규성 검정 : p-value 가 0.05이상이면 정규성을 보인다. 
shapiro.test(t_data$score)

3. 등분산성 검정 : 분산이 같은지 다른지에 따라 검증의 결과가 달라지기 때문이다.
                 p-value가 0.05이상이면 등분산이다. 
t_data_1<-t_data[t_data$group==1,]
t_data_2<-t_data[t_data$group==2,]
var.test(t_data_1$score,t_data_2$score)

4. t-test : var.equal은 등분산이면 T 이분산(등분산이 아닌거)는 F로 설정
t.test(t_data_1$score,t_data_2$score,var.equal=T)
= p-value 값이 0.05 이하가 나왔음으로 대립가설 채택!


대응 t-test의 수행(전/후 비교) ----------
before_op = c(137,119,117,122,132,110,114,117)
after_op = c(126,111,117,116,135,110,113,112)

t.test(before_op,after_op,paired=T)
= p-value 0.05 이상이 나와서 귀무가설 채택


3개 이상의 평균비교 시 분산분석 ----------

분산분석에서 등분산성 검정할 때는 var.test가 아니고 
bartlett.test(score~as.factor(group),data=anova_data)
oneway.test(score~group,data=anova_data,var.equal = T) / 이분산성일 때는 var.equal = F

등분산성 검정이 유의하다고 나오고 최종 분산분석까지 p-vaule에서 대립가설 채택하게 되면 사후검정실시 
LDuncan(a1, "group")

TukeyHSD(aov(score~as.character(group),data=anova_data))
plot(TukeyHSD(aov(score~as.character(group),data=anova_data)))
aov : one-way ANOVA 분석

-------------------------------------------------------------------------------------

10주차 보면 데이터 전처리, 변수생성 참고하기 좋음
train$year <- year(train$datetime)
train$month <- month(train$datetime)
train$day <- day(train$datetime)
train$hour <- hour(train$datetime)
train$weekday <- weekdays(train$datetime)

train %>%
  ggplot(aes(x=hour, y=month, fill=count))+
  geom_tile()+
  scale_fill_distiller(palette = "Blues",direction = 1) # direction = 1 은 밝기에 대한 오름차순 내림차순 느낌! 
  
--------------------------------------------------------------------------------------------------------
전체적인 과정

1. 데이터 불러오기 
   작업창 설정 ctrl + Shift + H
    train <- read.csv("bike.csv")

2. 데이터 파악
  head(train)
  summary(train)
  str(train)
  View(train)

3. 필요한 변수 생성 
	train$datetime <-ymd_hms(train$datetime)

	train$year <- year(train$datetime)
	train$month <- month(train$datetime)
	train$day <- day(train$datetime)
	train$hour <- hour(train$datetime)

4. 데이터 타입 변형시켜주기 - 범주형, 연속형을 구분해주는것은 중요!
	train$season= as.factor(train$season)
	train$weather<- as.factor(train$weather)
	train$holiday<- as.factor(train$holiday)
	train$workingday <- as.factor(train$workingday)
	train$weekday <- as.factor(train$weekday)
	train$year <- as.factor(train$year)
------------------------------------------------------------------------------------
1. 시각적 접근
	train %>% 
	  group_by(workingday) %>% 
	  summarise(count = sum(count)) %>% 
	  ggplot(aes(x=workingday, y=count, fill=workingday))+geom_bar(stat = "identity")
	  
2. 통계적 접근
**상관관계 분석 : 변수간의 연광성 확인
  1) na값 처리 후 상관관계 파악(제거, 중앙값, 평균값으로 대체 등등)
	cor(acs2,use="na.or.complete")	
  2) 시각화 
	pairs.panels(acs2)
	chart.Correlation(acs2, histogram=TRUE, pch=19)

가. 톡립표본 T검정(서로 다른 두 개의 그룹간의 평균 비교)
  1) 정규성 검정 shapiro.test() - 실무에선 생략하는 경우가 많음(표본의 개수가 30개가 넘으면)
  2) 등분산성 검정 var.test() 
	var.test(count~workingday,data=train)
  3) T검정 t.test(var.equal = T) or t.test(var.equal = F)
	t.test(count~workingday,data=train,var.equal = F)

나. 대응표본 T검정(전/후 비교)
  1) 정규성 검정 shapiro.test()
  2) T검정 t.test(paired = T) or wilcox.test(paired = T)

다. 분산분석(3개 이상의 집단 평균비교)
  1) 정규성 검정 shapiro.test() 
  2) 등분산성 검정 bartlett.test()
  3) F검정 oneway.test(var.equal = T) or oneway.test(var.equal = F)
  4) 사후검정 
	LDuncan(a1, "group")
	TukeyHSD(aov(score~as.character(group),data=anova_data))
	plot(TukeyHSD(aov(score~as.character(group),data=anova_data)))

라. 카이제곱 : 두 범주형 변수를 빈도 기반 검정실시  <- 요거는 다시 
  1) 적합도 검정
  2) 독립성 검정
	chisq.test(table(delivery$요일,delivery$업종))
	mosaicplot(t(table(delivery$요일,delivery$업종)),col=c("deepskyblue", "brown2"))
